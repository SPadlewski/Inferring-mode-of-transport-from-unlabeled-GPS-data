{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import pickle\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "#tf.compat.v1.\n",
    "print(tf.version.GIT_VERSION, tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/home/jupyter/Combined Trajectory_Label_Geolife')\n",
    "tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "sess = print(tf.Session(config=tf.ConfigProto(log_device_placement=True)))\n",
    "\n",
    "start_time = time.clock()\n",
    "np.random.seed(7)\n",
    "random.seed(7)\n",
    "\n",
    "filename = '../Combined Trajectory_Label_Geolife/Revised_KerasData_Smoothing.pickle'\n",
    "\n",
    "with open(filename, mode='rb') as f:\n",
    "    TotalInput, FinalLabel = pickle.load(f, encoding='latin1')  # Also can use the encoding 'iso-8859-1'\n",
    "\n",
    "NoClass = len(list(set(np.ndarray.flatten(FinalLabel))))\n",
    "Threshold = len(TotalInput[0, 0, :, 0])\n",
    "\n",
    "# Making training and test data: 80% Training, 20% Test\n",
    "Train_X, Test_X, Train_Y, Test_Y_ori = train_test_split(TotalInput, FinalLabel, test_size=0.20, random_state=7)\n",
    "\n",
    "Train_Y = np_utils.to_categorical(Train_Y, num_classes=NoClass)\n",
    "Test_Y = np_utils.to_categorical(Test_Y_ori, num_classes=NoClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n",
      "Device mapping: no known devices.\n",
      "<tensorflow.python.client.session.Session object at 0x7f05a1147150>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/62\n",
      "406/406 [==============================] - 43s 68ms/step - loss: 1.0941 - accuracy: 0.5951 - val_loss: 0.7597 - val_accuracy: 0.7548\n",
      "Epoch 2/62\n",
      "406/406 [==============================] - 27s 66ms/step - loss: 0.7687 - accuracy: 0.7446 - val_loss: 0.6796 - val_accuracy: 0.7814\n",
      "Epoch 3/62\n",
      "406/406 [==============================] - 27s 66ms/step - loss: 0.7239 - accuracy: 0.7620 - val_loss: 0.6549 - val_accuracy: 0.7925\n",
      "Epoch 4/62\n",
      "406/406 [==============================] - 27s 66ms/step - loss: 0.6838 - accuracy: 0.7760 - val_loss: 0.6404 - val_accuracy: 0.7938\n",
      "Epoch 5/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.6542 - accuracy: 0.7884 - val_loss: 0.6250 - val_accuracy: 0.8002\n",
      "Epoch 6/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.6316 - accuracy: 0.7921 - val_loss: 0.6099 - val_accuracy: 0.8016\n",
      "Epoch 7/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.6128 - accuracy: 0.8000 - val_loss: 0.6200 - val_accuracy: 0.7945\n",
      "Epoch 8/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.5893 - accuracy: 0.8073 - val_loss: 0.6015 - val_accuracy: 0.8069\n",
      "Epoch 9/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.5714 - accuracy: 0.8133 - val_loss: 0.6112 - val_accuracy: 0.8080\n",
      "Epoch 10/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.5568 - accuracy: 0.8180 - val_loss: 0.6005 - val_accuracy: 0.8113\n",
      "Epoch 11/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.5398 - accuracy: 0.8246 - val_loss: 0.5924 - val_accuracy: 0.8129\n",
      "Epoch 12/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.5204 - accuracy: 0.8306 - val_loss: 0.5937 - val_accuracy: 0.8149\n",
      "Epoch 13/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.4993 - accuracy: 0.8382 - val_loss: 0.6018 - val_accuracy: 0.8133\n",
      "Epoch 14/62\n",
      "406/406 [==============================] - 26s 64ms/step - loss: 0.4912 - accuracy: 0.8408 - val_loss: 0.6047 - val_accuracy: 0.8163\n",
      "Epoch 15/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.4725 - accuracy: 0.8466 - val_loss: 0.6128 - val_accuracy: 0.8157\n",
      "Epoch 16/62\n",
      "406/406 [==============================] - 27s 65ms/step - loss: 0.4616 - accuracy: 0.8493 - val_loss: 0.6329 - val_accuracy: 0.8144\n",
      "Epoch 17/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.4441 - accuracy: 0.8550 - val_loss: 0.6315 - val_accuracy: 0.8133\n",
      "Epoch 18/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.4306 - accuracy: 0.8603 - val_loss: 0.6377 - val_accuracy: 0.8076\n",
      "Epoch 19/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.4209 - accuracy: 0.8622 - val_loss: 0.6284 - val_accuracy: 0.8101\n",
      "Epoch 20/62\n",
      "406/406 [==============================] - 27s 66ms/step - loss: 0.4029 - accuracy: 0.8661 - val_loss: 0.6774 - val_accuracy: 0.8092\n",
      "Epoch 21/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3965 - accuracy: 0.8683 - val_loss: 0.6683 - val_accuracy: 0.8107\n",
      "Epoch 22/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3811 - accuracy: 0.8780 - val_loss: 0.6811 - val_accuracy: 0.8130\n",
      "Epoch 23/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3794 - accuracy: 0.8763 - val_loss: 0.6621 - val_accuracy: 0.8083\n",
      "Epoch 24/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3618 - accuracy: 0.8818 - val_loss: 0.6913 - val_accuracy: 0.8107\n",
      "Epoch 25/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3576 - accuracy: 0.8820 - val_loss: 0.7180 - val_accuracy: 0.8143\n",
      "Epoch 26/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3458 - accuracy: 0.8843 - val_loss: 0.7430 - val_accuracy: 0.8112\n",
      "Epoch 27/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3370 - accuracy: 0.8885 - val_loss: 0.7122 - val_accuracy: 0.8166\n",
      "Epoch 28/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3315 - accuracy: 0.8907 - val_loss: 0.7485 - val_accuracy: 0.8100\n",
      "Epoch 29/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3266 - accuracy: 0.8906 - val_loss: 0.7530 - val_accuracy: 0.8112\n",
      "Epoch 30/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3099 - accuracy: 0.8976 - val_loss: 0.7393 - val_accuracy: 0.8118\n",
      "Epoch 31/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3036 - accuracy: 0.8975 - val_loss: 0.7778 - val_accuracy: 0.8140\n",
      "Epoch 32/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.3076 - accuracy: 0.8963 - val_loss: 0.7666 - val_accuracy: 0.8155\n",
      "Epoch 33/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2985 - accuracy: 0.9019 - val_loss: 0.7593 - val_accuracy: 0.8189\n",
      "Epoch 34/62\n",
      "406/406 [==============================] - 27s 66ms/step - loss: 0.2851 - accuracy: 0.9034 - val_loss: 0.7645 - val_accuracy: 0.8172\n",
      "Epoch 35/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2780 - accuracy: 0.9050 - val_loss: 0.7648 - val_accuracy: 0.8166\n",
      "Epoch 36/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2820 - accuracy: 0.9040 - val_loss: 0.8347 - val_accuracy: 0.8172\n",
      "Epoch 37/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2712 - accuracy: 0.9090 - val_loss: 0.8227 - val_accuracy: 0.8186\n",
      "Epoch 38/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2668 - accuracy: 0.9129 - val_loss: 0.8180 - val_accuracy: 0.8172\n",
      "Epoch 39/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2605 - accuracy: 0.9129 - val_loss: 0.7935 - val_accuracy: 0.8175\n",
      "Epoch 40/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2593 - accuracy: 0.9136 - val_loss: 0.8091 - val_accuracy: 0.8192\n",
      "Epoch 41/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2488 - accuracy: 0.9173 - val_loss: 0.7907 - val_accuracy: 0.8181\n",
      "Epoch 42/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2420 - accuracy: 0.9193 - val_loss: 0.8165 - val_accuracy: 0.8161\n",
      "Epoch 43/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2561 - accuracy: 0.9125 - val_loss: 0.7879 - val_accuracy: 0.8147\n",
      "Epoch 44/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2456 - accuracy: 0.9167 - val_loss: 0.7876 - val_accuracy: 0.8129\n",
      "Epoch 45/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2412 - accuracy: 0.9173 - val_loss: 0.8435 - val_accuracy: 0.8158\n",
      "Epoch 46/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2484 - accuracy: 0.9178 - val_loss: 0.7859 - val_accuracy: 0.8172\n",
      "Epoch 47/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2220 - accuracy: 0.9239 - val_loss: 0.8263 - val_accuracy: 0.8169\n",
      "Epoch 48/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2262 - accuracy: 0.9241 - val_loss: 0.8735 - val_accuracy: 0.8132\n",
      "Epoch 49/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2166 - accuracy: 0.9271 - val_loss: 0.8534 - val_accuracy: 0.8112\n",
      "Epoch 50/62\n",
      "406/406 [==============================] - 26s 64ms/step - loss: 0.2287 - accuracy: 0.9208 - val_loss: 0.8738 - val_accuracy: 0.8174\n",
      "Epoch 51/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2227 - accuracy: 0.9247 - val_loss: 0.8366 - val_accuracy: 0.8157\n",
      "Epoch 52/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2200 - accuracy: 0.9270 - val_loss: 0.8750 - val_accuracy: 0.8106\n",
      "Epoch 53/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2152 - accuracy: 0.9246 - val_loss: 0.8638 - val_accuracy: 0.8149\n",
      "Epoch 54/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2068 - accuracy: 0.9295 - val_loss: 0.9238 - val_accuracy: 0.8089\n",
      "Epoch 55/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2164 - accuracy: 0.9277 - val_loss: 0.8583 - val_accuracy: 0.8186\n",
      "Epoch 56/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2070 - accuracy: 0.9291 - val_loss: 0.9139 - val_accuracy: 0.8194\n",
      "Epoch 57/62\n",
      "406/406 [==============================] - 27s 65ms/step - loss: 0.2119 - accuracy: 0.9271 - val_loss: 0.9036 - val_accuracy: 0.8164\n",
      "Epoch 58/62\n",
      "406/406 [==============================] - 27s 65ms/step - loss: 0.2131 - accuracy: 0.9288 - val_loss: 0.8874 - val_accuracy: 0.8143\n",
      "Epoch 59/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2020 - accuracy: 0.9324 - val_loss: 0.8285 - val_accuracy: 0.8163\n",
      "Epoch 60/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.1938 - accuracy: 0.9351 - val_loss: 0.7876 - val_accuracy: 0.8107\n",
      "Epoch 61/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.2155 - accuracy: 0.9251 - val_loss: 0.8730 - val_accuracy: 0.8157\n",
      "Epoch 62/62\n",
      "406/406 [==============================] - 26s 65ms/step - loss: 0.1893 - accuracy: 0.9372 - val_loss: 0.9159 - val_accuracy: 0.8106\n"
     ]
    }
   ],
   "source": [
    "# Model and Compile\n",
    "model = Sequential()\n",
    "activ = 'relu'\n",
    "model.add(Conv2D(32, (1, 3), strides=(1, 1), padding='same', activation=activ, input_shape=(1, Threshold, 4)))\n",
    "model.add(Conv2D(32, (1, 3), strides=(1, 1), padding='same', activation=activ))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (1, 3), strides=(1, 1), padding='same', activation=activ))\n",
    "model.add(Conv2D(64, (1, 3), strides=(1, 1), padding='same', activation=activ))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (1, 3), strides=(1, 1), padding='same', activation=activ))\n",
    "model.add(Conv2D(128, (1, 3), strides=(1, 1), padding='same', activation=activ))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "A = model.output_shape\n",
    "model.add(Dense(int(A[1] * 1/4.), activation=activ))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(NoClass, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "offline_history = model.fit(Train_X, Train_Y, epochs=62, batch_size=64, shuffle=False,\n",
    "                            validation_data=(Test_X, Test_Y))\n",
    "hist = offline_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the test and training score for varying number of epochs.\n",
    "#with open('Revised_accuracy_history_largeEpoch_NoSmoothing.pickle', 'wb') as f:\n",
    "#    pickle.dump([hist.epoch, hist.history['accuracy'], hist.history['val_accuracy']], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "filename = 'models/model_CNN_7.h5'\n",
    "model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Test_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba938df8e9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculating the test accuracy, precision, recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mPred_Label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Test_X' is not defined"
     ]
    }
   ],
   "source": [
    "A = np.argmax(hist.history['val_accuracy'])\n",
    "print('the optimal epoch size: {}, the value of high accuracy {}'.format(hist.epoch[A], np.max(hist.history['val_accuracy'])))\n",
    "\n",
    "# Calculating the test accuracy, precision, recall\n",
    "Pred = model.predict(Test_X, batch_size=32)\n",
    "Pred_Label = np.argmax(Pred, axis=1)\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(Pred_Label)):\n",
    "    if Pred_Label[i] == Test_Y_ori[i]:\n",
    "        counter += 1\n",
    "Accuracy = counter * 1./len(Pred_Label)\n",
    "\n",
    "ActualPositive = []\n",
    "for i in range(NoClass):\n",
    "    AA = np.where(Test_Y_ori == i)[0]\n",
    "    ActualPositive.append(AA)\n",
    "\n",
    "PredictedPositive = []\n",
    "for i in range(NoClass):\n",
    "    AA = np.where(Pred_Label == i)[0]\n",
    "    PredictedPositive.append(AA)\n",
    "\n",
    "TruePositive = []\n",
    "FalsePositive = []\n",
    "for i in range(NoClass):\n",
    "    AA = []\n",
    "    BB = []\n",
    "    for j in PredictedPositive[i]:\n",
    "        if Pred_Label[j] == Test_Y_ori[j]:\n",
    "            AA.append(j)\n",
    "        else:\n",
    "            BB.append(j)\n",
    "    TruePositive.append(AA)\n",
    "    FalsePositive.append(BB)\n",
    "Precision = []\n",
    "Recall = []\n",
    "for i in range(NoClass):\n",
    "    Precision.append(len(TruePositive[i]) * 1./len(PredictedPositive[i]))\n",
    "    Recall.append(len(TruePositive[i]) * 1./len(ActualPositive[i]))\n",
    "\n",
    "ConfusionM = confusion_matrix(list(Test_Y_ori), Pred_Label, labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "print('Confusion Matrix: ', ConfusionM)\n",
    "print(\"Recall\", Recall)\n",
    "print('precision', Precision)\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
