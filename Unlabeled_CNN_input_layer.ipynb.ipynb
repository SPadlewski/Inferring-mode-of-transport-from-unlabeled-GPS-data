{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import skmob\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "from shapely.geometry import Point\n",
    "from skmob.preprocessing import filtering\n",
    "from skmob.preprocessing import detection\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "df_dis = pd.read_pickle('Data/stages_40_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripID</th>\n",
       "      <th>epoch_rate</th>\n",
       "      <th>datetime</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>tr_no_points</th>\n",
       "      <th>delta_time</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lon</th>\n",
       "      <th>distance</th>\n",
       "      <th>...</th>\n",
       "      <th>acc</th>\n",
       "      <th>walk_stage_poss</th>\n",
       "      <th>walk_stage_poss_shift</th>\n",
       "      <th>cumsum</th>\n",
       "      <th>tripID_shift</th>\n",
       "      <th>cumsum_trip</th>\n",
       "      <th>stageID</th>\n",
       "      <th>stageID_step3</th>\n",
       "      <th>certain_stage</th>\n",
       "      <th>stageID_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>756</td>\n",
       "      <td>35</td>\n",
       "      <td>2021-05-18 16:55:47+00:00</td>\n",
       "      <td>51.379045</td>\n",
       "      <td>-0.110588</td>\n",
       "      <td>254</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.380710</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>250.029344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007460</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>756.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>756</td>\n",
       "      <td>35</td>\n",
       "      <td>2021-05-18 16:56:32+00:00</td>\n",
       "      <td>51.380710</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>254</td>\n",
       "      <td>46.0</td>\n",
       "      <td>51.378565</td>\n",
       "      <td>-0.113385</td>\n",
       "      <td>240.143805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>756.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>756</td>\n",
       "      <td>35</td>\n",
       "      <td>2021-05-18 16:57:18+00:00</td>\n",
       "      <td>51.378565</td>\n",
       "      <td>-0.113385</td>\n",
       "      <td>254</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.379508</td>\n",
       "      <td>-0.111344</td>\n",
       "      <td>176.635759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>756.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>756</td>\n",
       "      <td>35</td>\n",
       "      <td>2021-05-18 16:58:03+00:00</td>\n",
       "      <td>51.379508</td>\n",
       "      <td>-0.111344</td>\n",
       "      <td>254</td>\n",
       "      <td>46.0</td>\n",
       "      <td>51.376619</td>\n",
       "      <td>-0.107591</td>\n",
       "      <td>414.233449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>756.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>756</td>\n",
       "      <td>35</td>\n",
       "      <td>2021-05-18 16:58:49+00:00</td>\n",
       "      <td>51.376619</td>\n",
       "      <td>-0.107591</td>\n",
       "      <td>254</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.370251</td>\n",
       "      <td>-0.105662</td>\n",
       "      <td>721.095257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>756.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692741</th>\n",
       "      <td>4673660</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-17 13:56:24+00:00</td>\n",
       "      <td>51.982631</td>\n",
       "      <td>-0.224228</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.982646</td>\n",
       "      <td>-0.224235</td>\n",
       "      <td>1.736915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038078</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4673660.0</td>\n",
       "      <td>False</td>\n",
       "      <td>355364</td>\n",
       "      <td>229805</td>\n",
       "      <td>0</td>\n",
       "      <td>174885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692742</th>\n",
       "      <td>4673660</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-17 13:56:28+00:00</td>\n",
       "      <td>51.982646</td>\n",
       "      <td>-0.224235</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.982661</td>\n",
       "      <td>-0.224259</td>\n",
       "      <td>2.346163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4673660.0</td>\n",
       "      <td>False</td>\n",
       "      <td>355364</td>\n",
       "      <td>229805</td>\n",
       "      <td>0</td>\n",
       "      <td>174885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692743</th>\n",
       "      <td>4673660</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-17 13:56:32+00:00</td>\n",
       "      <td>51.982661</td>\n",
       "      <td>-0.224259</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.982668</td>\n",
       "      <td>-0.224269</td>\n",
       "      <td>1.038590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190943</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4673660.0</td>\n",
       "      <td>False</td>\n",
       "      <td>355364</td>\n",
       "      <td>229805</td>\n",
       "      <td>0</td>\n",
       "      <td>174885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692744</th>\n",
       "      <td>4673660</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-17 13:56:34+00:00</td>\n",
       "      <td>51.982668</td>\n",
       "      <td>-0.224269</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.982668</td>\n",
       "      <td>-0.224273</td>\n",
       "      <td>0.274818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4673660.0</td>\n",
       "      <td>False</td>\n",
       "      <td>355364</td>\n",
       "      <td>229805</td>\n",
       "      <td>0</td>\n",
       "      <td>174885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692745</th>\n",
       "      <td>4673660</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-17 13:56:36+00:00</td>\n",
       "      <td>51.982668</td>\n",
       "      <td>-0.224273</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.519804</td>\n",
       "      <td>-0.131730</td>\n",
       "      <td>0.274818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4673660.0</td>\n",
       "      <td>False</td>\n",
       "      <td>355364</td>\n",
       "      <td>229805</td>\n",
       "      <td>0</td>\n",
       "      <td>174885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3326695 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tripID  epoch_rate                  datetime        lat       lon  \\\n",
       "12           756          35 2021-05-18 16:55:47+00:00  51.379045 -0.110588   \n",
       "13           756          35 2021-05-18 16:56:32+00:00  51.380710 -0.113000   \n",
       "14           756          35 2021-05-18 16:57:18+00:00  51.378565 -0.113385   \n",
       "15           756          35 2021-05-18 16:58:03+00:00  51.379508 -0.111344   \n",
       "16           756          35 2021-05-18 16:58:49+00:00  51.376619 -0.107591   \n",
       "...          ...         ...                       ...        ...       ...   \n",
       "3692741  4673660           3 2021-05-17 13:56:24+00:00  51.982631 -0.224228   \n",
       "3692742  4673660           3 2021-05-17 13:56:28+00:00  51.982646 -0.224235   \n",
       "3692743  4673660           3 2021-05-17 13:56:32+00:00  51.982661 -0.224259   \n",
       "3692744  4673660           3 2021-05-17 13:56:34+00:00  51.982668 -0.224269   \n",
       "3692745  4673660           3 2021-05-17 13:56:36+00:00  51.982668 -0.224273   \n",
       "\n",
       "         tr_no_points  delta_time   dest_lat  dest_lon    distance  ...  \\\n",
       "12                254        45.0  51.380710 -0.113000  250.029344  ...   \n",
       "13                254        46.0  51.378565 -0.113385  240.143805  ...   \n",
       "14                254        45.0  51.379508 -0.111344  176.635759  ...   \n",
       "15                254        46.0  51.376619 -0.107591  414.233449  ...   \n",
       "16                254        45.0  51.370251 -0.105662  721.095257  ...   \n",
       "...               ...         ...        ...       ...         ...  ...   \n",
       "3692741            21         4.0  51.982646 -0.224235    1.736915  ...   \n",
       "3692742            21         4.0  51.982661 -0.224259    2.346163  ...   \n",
       "3692743            21         2.0  51.982668 -0.224269    1.038590  ...   \n",
       "3692744            21         2.0  51.982668 -0.224273    0.274818  ...   \n",
       "3692745            21         2.0  51.519804 -0.131730    0.274818  ...   \n",
       "\n",
       "              acc  walk_stage_poss  walk_stage_poss_shift  cumsum  \\\n",
       "12       0.007460                0                    1.0    True   \n",
       "13       0.028158                0                    0.0   False   \n",
       "14       0.112885                0                    0.0   False   \n",
       "15       0.152593                0                    0.0   False   \n",
       "16       0.142534                0                    0.0   False   \n",
       "...           ...              ...                    ...     ...   \n",
       "3692741  0.038078                0                    0.0   False   \n",
       "3692742  0.016811                0                    0.0   False   \n",
       "3692743  0.190943                0                    0.0   False   \n",
       "3692744  0.000000                0                    0.0   False   \n",
       "3692745  0.000000                0                    0.0   False   \n",
       "\n",
       "         tripID_shift  cumsum_trip  stageID  stageID_step3  certain_stage  \\\n",
       "12              756.0        False        5              5              1   \n",
       "13              756.0        False        5              5              1   \n",
       "14              756.0        False        5              5              1   \n",
       "15              756.0        False        5              5              1   \n",
       "16              756.0        False        5              5              1   \n",
       "...               ...          ...      ...            ...            ...   \n",
       "3692741     4673660.0        False   355364         229805              0   \n",
       "3692742     4673660.0        False   355364         229805              0   \n",
       "3692743     4673660.0        False   355364         229805              0   \n",
       "3692744     4673660.0        False   355364         229805              0   \n",
       "3692745     4673660.0        False   355364         229805              0   \n",
       "\n",
       "         stageID_final  \n",
       "12                   5  \n",
       "13                   5  \n",
       "14                   5  \n",
       "15                   5  \n",
       "16                   5  \n",
       "...                ...  \n",
       "3692741         174885  \n",
       "3692742         174885  \n",
       "3692743         174885  \n",
       "3692744         174885  \n",
       "3692745         174885  \n",
       "\n",
       "[3326695 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dis#stageID_final.nunique()#stageID_final#54430 and 147028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing datetime format\n",
    "df_dis['bench']=np.datetime64('1899-12-30')\n",
    "df_dis['bench']=df_dis['bench'].dt.tz_localize('UTC')\n",
    "\n",
    "z=df_dis['datetime']\n",
    "x=(df_dis['datetime']-df_dis['bench'])\n",
    "df_dis['timestamp']=x.dt.days + z.dt.hour/24 + z.dt.minute / (24. * 60.) + z.dt.second / (24. * 3600.)\n",
    "df_dis=df_dis.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting needed columns\n",
    "df_dis=df_dis[['lat','lon','timestamp','stageID_final']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting df_dis to numpy array\n",
    "df_dis_array=df_dis.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating proximity channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "railStop_gdf_en = gpd.read_file(\"GIS/EN_gis_osm_transport_free_1.shp\",crs='EPSG:4326')\n",
    "busStop_gdf_en=railStop_gdf_en[(railStop_gdf_en.fclass==\"bus_station\")|(railStop_gdf_en.fclass==\"bus_stop\")]\n",
    "railStop_gdf_en=railStop_gdf_en[(railStop_gdf_en.fclass==\"railway_station\")]\n",
    "\n",
    "\n",
    "railStop_gdf_sc = gpd.read_file(\"GIS/SC_gis_osm_transport_free_1.shp\",crs='EPSG:4326')\n",
    "busStop_gdf_sc=railStop_gdf_sc[(railStop_gdf_sc.fclass==\"bus_station\")|(railStop_gdf_sc.fclass==\"bus_stop\")]\n",
    "railStop_gdf_sc=railStop_gdf_sc[(railStop_gdf_sc.fclass==\"railway_station\")]\n",
    "\n",
    "railStop_gdf_wa = gpd.read_file(\"GIS/WA_gis_osm_transport_free_1.shp\",crs='EPSG:4326')\n",
    "busStop_gdf_wa=railStop_gdf_wa[(railStop_gdf_wa.fclass==\"bus_station\")|(railStop_gdf_wa.fclass==\"bus_stop\")]\n",
    "railStop_gdf_wa=railStop_gdf_wa[(railStop_gdf_wa.fclass==\"railway_station\")]\n",
    "\n",
    "\n",
    "railStop_gdf_ni = gpd.read_file(\"GIS/NI_rail.shp\",crs='EPSG:4326')\n",
    "busStop_gdf_ni = gpd.read_file(\"GIS/NI_bus.shp\",crs='EPSG:4326')\n",
    "\n",
    "\n",
    "railStop_gdf = railStop_gdf_en.append(railStop_gdf_wa)\n",
    "railStop_gdf = railStop_gdf.append(railStop_gdf_sc)\n",
    "railStop_gdf = railStop_gdf.append(railStop_gdf_ni)\n",
    "\n",
    "busStop_gdf = busStop_gdf_en.append(busStop_gdf_wa)\n",
    "busStop_gdf = busStop_gdf.append(busStop_gdf_sc)\n",
    "busStop_gdf = busStop_gdf.append(busStop_gdf_ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficStop_gdf_wa = gpd.read_file(\"GIS/WA_gis_osm_traffic_free_1.shp\",crs='EPSG:4326')\n",
    "trafficStop_gdf_wa=trafficStop_gdf_wa[(trafficStop_gdf_wa.fclass==\"crossing\")|(trafficStop_gdf_wa.fclass==\"motorway_junction\")|(trafficStop_gdf_wa.fclass==\"traffic_signals\")]\n",
    "\n",
    "trafficStop_gdf_sc = gpd.read_file(\"GIS/SC_gis_osm_traffic_free_1.shp\",crs='EPSG:4326')\n",
    "trafficStop_gdf_sc=trafficStop_gdf_sc[(trafficStop_gdf_sc.fclass==\"crossing\")|(trafficStop_gdf_sc.fclass==\"motorway_junction\")|(trafficStop_gdf_sc.fclass==\"traffic_signals\")]\n",
    "\n",
    "trafficStop_gdf_en = gpd.read_file(\"GIS/EN_gis_osm_traffic_free_1.shp\",crs='EPSG:4326')\n",
    "trafficStop_gdf_en=trafficStop_gdf_en[(trafficStop_gdf_en.fclass==\"crossing\")|(trafficStop_gdf_en.fclass==\"motorway_junction\")|(trafficStop_gdf_en.fclass==\"traffic_signals\")]\n",
    "\n",
    "trafficStop_gdf_ni = gpd.read_file(\"GIS/NI_traffic.shp\",crs='EPSG:4326')\n",
    "\n",
    "trafficStop_gdf = trafficStop_gdf_en.append(trafficStop_gdf_wa)\n",
    "trafficStop_gdf = trafficStop_gdf.append(trafficStop_gdf_sc)\n",
    "trafficStop_gdf = trafficStop_gdf.append(trafficStop_gdf_ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191297, 14)\n",
      "(3562, 14)\n",
      "(252667, 14)\n"
     ]
    }
   ],
   "source": [
    "print(trafficStop_gdf.shape)\n",
    "print(railStop_gdf.shape)\n",
    "print(busStop_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251717, 5)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(186753, 5)\n",
    "(3499, 5)\n",
    "(251717, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest(src_points, candidates, k_neighbors=1):\n",
    "    \"\"\"Find nearest neighbors for all source points from a set of candidate points\"\"\"\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='haversine')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    # Get closest indices and distances (i.e. array at index 0)\n",
    "    # note: for the second closest points, you would take index 1, etc.\n",
    "    closest = indices[0]\n",
    "    closest_dist = distances[0]\n",
    "\n",
    "    # Return indices and distances\n",
    "    return (closest, closest_dist)\n",
    "\n",
    "\n",
    "def nearest_neighbor(left_gdf, right_gdf, return_dist=False):\n",
    "    \"\"\"\n",
    "    For each point in left_gdf, find closest point in right GeoDataFrame and return them.\n",
    "    \n",
    "    NOTICE: Assumes that the input Points are in WGS84 projection (lat/lon).\n",
    "    \"\"\"\n",
    "    \n",
    "    left_geom_col = left_gdf.geometry.name\n",
    "    right_geom_col = right_gdf.geometry.name\n",
    "    \n",
    "    # Ensure that index in right gdf is formed of sequential numbers\n",
    "    right = right_gdf.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Parse coordinates from points and insert them into a numpy array as RADIANS\n",
    "    # Notice: should be in Lat/Lon format \n",
    "    left_radians = np.array(left_gdf[left_geom_col].apply(lambda geom: (geom.y * np.pi / 180, geom.x * np.pi / 180)).to_list())\n",
    "    right_radians = np.array(right[right_geom_col].apply(lambda geom: (geom.y * np.pi / 180, geom.x * np.pi / 180)).to_list())\n",
    "    \n",
    "    # Find the nearest points\n",
    "    # -----------------------\n",
    "    # closest ==> index in right_gdf that corresponds to the closest point\n",
    "    # dist ==> distance between the nearest neighbors (in meters)\n",
    "    \n",
    "    closest, dist = get_nearest(src_points=left_radians, candidates=right_radians)\n",
    "\n",
    "    # Return points from right GeoDataFrame that are closest to points in left GeoDataFrame\n",
    "    closest_points = right.loc[closest]\n",
    "    \n",
    "    # Ensure that the index corresponds the one in left_gdf\n",
    "    closest_points = closest_points.reset_index(drop=True)\n",
    "    \n",
    "    # Add distance if requested \n",
    "    if return_dist:\n",
    "        # Convert to meters from radians\n",
    "        earth_radius = 6371000  # meters\n",
    "        closest_points['distance'] = dist * earth_radius\n",
    "        \n",
    "    return closest_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46min 35s, sys: 4.52 s, total: 46min 39s\n",
      "Wall time: 46min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#32min or 1h 17min\n",
    "RailStop_dis=[]\n",
    "TrafficStop_dis=[]\n",
    "BusStop_dis=[]\n",
    "\n",
    "Data = df_dis_array\n",
    "\n",
    "arr1lat = np.ravel(Data[:,0])\n",
    "arr1lon = np.ravel(Data[:,1])\n",
    "df1 = pd.DataFrame({'lat':arr1lat, 'lon':arr1lon})\n",
    "df1['coords'] = list(zip( df1['lon'],df1['lat']))\n",
    "df1['coords'] = df1['coords'].apply(Point)\n",
    "gdf1 = gpd.GeoDataFrame(df1, geometry='coords')\n",
    "    \n",
    "closest_stops_bus = nearest_neighbor(gdf1 ,busStop_gdf, return_dist=True)\n",
    "closest_stops_traffic = nearest_neighbor(gdf1 ,trafficStop_gdf, return_dist=True)\n",
    "closest_stops_rail = nearest_neighbor(gdf1 ,railStop_gdf, return_dist=True)\n",
    "    \n",
    "bus_dis = closest_stops_bus['distance'].values\n",
    "traffic_dis = closest_stops_traffic['distance'].values\n",
    "rail_dis = closest_stops_rail['distance'].values\n",
    "    \n",
    "BusStop_dis.append(bus_dis)\n",
    "TrafficStop_dis.append(traffic_dis)\n",
    "RailStop_dis.append(rail_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving results\n",
    "with open('Data/Proximity_Unlabeled_40_final.pickle', 'wb') as f:\n",
    "    pickle.dump([BusStop_dis,TrafficStop_dis,RailStop_dis], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/Proximity_Unlabeled_40_final.pickle'\n",
    "with open(filename, 'rb') as f:\n",
    "    BusStop_dis,TrafficStop_dis,RailStop_dis = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.64 s, sys: 192 ms, total: 6.84 s\n",
      "Wall time: 6.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#dividing stages into segments with 200 points\n",
    "Data=df_dis_array\n",
    "# SegmentNumber: indicate the length of each Segment\n",
    "SegmentNumber = []\n",
    "# Stage: For each created segment, we need only one mode to be assigned to.\n",
    "# Remove the segments with less than 10 GPS points. \n",
    "# Also break the stages with more than threshold GPS points into more segment\n",
    "BusData=BusStop_dis[0]\n",
    "RailData=RailStop_dis[0]\n",
    "TrafficData=TrafficStop_dis[0]\n",
    "\n",
    "Bus_All_Segment=[]\n",
    "Rail_All_Segment=[]\n",
    "Traffic_All_Segment=[]\n",
    "Stage = []\n",
    "Data_All_Segment = []  # Each of its element is a list that shows the data for each segment (lat, long, time)\n",
    "threshold = 200  # fixed of number of GPS points for each segment\n",
    "i = 0\n",
    "while i <= (len(Data) - 1):\n",
    "    No = 0\n",
    "    StageID = Data[i, 3]\n",
    "    Counter = 0\n",
    "    # index: save the segment indices when an Segment is being created and concatenate all in the remove\n",
    "    index = []\n",
    "    # First, we always have an segment with one GPS point.\n",
    "    while i <= (len(Data) - 1) and Data[i, 3] == StageID and Counter < threshold:\n",
    "        Counter += 1\n",
    "        index.append(i)\n",
    "        i += 1\n",
    "\n",
    "    if Counter >= 10:  # Remove all segment that have less than 10 GPS points\n",
    "        SegmentNumber.append(Counter)\n",
    "        Data_For_Segment = [Data[i, 0:3] for i in index]#[0:3]\n",
    "        Data_For_Segment = np.array(Data_For_Segment, dtype=float)\n",
    "        Data_All_Segment.append(Data_For_Segment)            \n",
    "        \n",
    "        Bus_For_Segment=[BusData[i] for i in index]\n",
    "        Bus_All_Segment.append(Bus_For_Segment)\n",
    "        \n",
    "        Rail_For_Segment=[RailData[i] for i in index]\n",
    "        Rail_All_Segment.append(Rail_For_Segment)\n",
    "        \n",
    "        Traffic_For_Segment=[TrafficData[i] for i in index]\n",
    "        Traffic_All_Segment.append(Traffic_For_Segment)\n",
    "        Stage.append(StageID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72977"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "SegmentID = [*range(0, len(Stage))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving results\n",
    "with open('Data/Proximity+200_Unlabeled_40_final.pickle', 'wb') as f:\n",
    "    pickle.dump([Bus_All_Segment,SegmentID, Rail_All_Segment, Traffic_All_Segment, Stage, Data_All_Segment, SegmentNumber], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/Proximity+200_Unlabeled_40_final.pickle'\n",
    "with open(filename, 'rb') as f:\n",
    "    Bus_All_Segment,SegmentID ,Rail_All_Segment, Traffic_All_Segment, Stage, Data_All_Segment, SegmentNumber = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Motion channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_Segment_InSequence checks the number of GPS points for each instance in all Stages\n",
    "Total_Segment_InSequence = []\n",
    "# Save the 4 channels for each user separately\n",
    "Total_RelativeDistance = []\n",
    "Total_Speed = []\n",
    "Total_Acceleration = []\n",
    "Total_Jerk = []\n",
    "Total_BearingRate = []\n",
    "Total_Stage = []\n",
    "Total_SegmentNumber = []\n",
    "Total_Outlier = []\n",
    "Total_Descriptive_Stat = []\n",
    "Total_Delta_Time = []\n",
    "Total_Velocity_Change = []\n",
    "Total_BusLine = []\n",
    "Total_Railway = []\n",
    "Total_Traffic = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 7s, sys: 488 ms, total: 11min 7s\n",
      "Wall time: 11min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Calculating Channels for segemnts\n",
    "# Count the number of times that NoOfOutlier happens\n",
    "NoOfOutlier = 0\n",
    "\n",
    "Stage = [int(i) for i in Stage] #Stage to int\n",
    "\n",
    "    \n",
    "#creating empty list for every pair of points\n",
    "RelativeDistance = [[] for _ in range(len(SegmentNumber))] \n",
    "Speed = [[] for _ in range(len(SegmentNumber))]\n",
    "Acceleration = [[] for _ in range(len(SegmentNumber))]\n",
    "Jerk = [[] for _ in range(len(SegmentNumber))]\n",
    "Bearing = [[] for _ in range(len(SegmentNumber))]\n",
    "BearingRate = [[] for _ in range(len(SegmentNumber))]\n",
    "Delta_Time = [[] for _ in range(len(SegmentNumber))]\n",
    "Velocity_Change = [[] for _ in range(len(SegmentNumber))]\n",
    "User_outlier = []\n",
    "    \n",
    "###### Create channels for every Segment (k) \n",
    "for k in range(len(SegmentNumber)):\n",
    "    Data = Data_All_Segment[k] # a list of points in a Segment\n",
    "    # Temp_RD, Temp_SP are temporary relative distance and speed before checking for their length\n",
    "    Temp_Speed = []\n",
    "    Temp_RD = []\n",
    "    outlier = []\n",
    "    for i in range(len(Data) - 1):\n",
    "        A = (Data[i, 0], Data[i, 1])\n",
    "        B = (Data[i+1, 0], Data[i+1, 1])\n",
    "        Temp_RD.append(geodesic(A, B).meters)\n",
    "        Delta_Time[k].append((Data[i + 1, 2] - Data[i, 2]) * 24. * 3600 + 1)  # Add one second to prevent zero time\n",
    "        S = Temp_RD[i] / Delta_Time[k][i]\n",
    "        if S > 62.5 or S < 0: # max speed of the fastest rail in the UK\n",
    "            outlier.append(i)\n",
    "        Temp_Speed.append(S)\n",
    "            \n",
    "        #Calculating Bearing\n",
    "        y = math.sin(math.radians(Data[i+1, 1]) - math.radians(Data[i, 1])) * math.radians(math.cos(Data[i+1, 0]))\n",
    "        x = math.radians(math.cos(Data[i, 0])) * math.radians(math.sin(Data[i+1, 0])) - \\\n",
    "        math.radians(math.sin(Data[i, 0])) * math.radians(math.cos(Data[i+1, 0])) \\\n",
    "            * math.radians(math.cos(Data[i+1, 1]) - math.radians(Data[i, 1]))\n",
    "        # Convert radian from -pi to pi to [0, 360] degree\n",
    "        b = (math.atan2(y, x) * 180. / math.pi + 360) % 360\n",
    "        Bearing[k].append(b)\n",
    "\n",
    "        \n",
    "    # End of operation of relative distance, speed, and bearing for one Segment\n",
    "        \n",
    "    # Now remove all outliers (exceeding max speed) in the current Segment\n",
    "    Temp_Speed = [i for j, i in enumerate(Temp_Speed) if j not in outlier]        \n",
    "    if len(Temp_Speed) < 10:\n",
    "        SegmentNumber[k] = 0\n",
    "        NoOfOutlier += 1\n",
    "        continue\n",
    "    Speed[k] = Temp_Speed\n",
    "    Speed[k].append(Speed[k][-1])\n",
    "\n",
    "    # Now remove all outlier Segments, where their speed exceeds the max speed.\n",
    "    # Then, remove their corresponding points from other channels.\n",
    "    Bus_All_Segment[k] = [i for j, i in enumerate(Bus_All_Segment[k]) if j not in outlier]\n",
    "    Rail_All_Segment[k] = [i for j, i in enumerate(Rail_All_Segment[k]) if j not in outlier]\n",
    "    Traffic_All_Segment[k] = [i for j, i in enumerate(Traffic_All_Segment[k]) if j not in outlier]                               \n",
    "    RelativeDistance[k] = Temp_RD\n",
    "    RelativeDistance[k] = [i for j, i in enumerate(RelativeDistance[k]) if j not in outlier]\n",
    "    RelativeDistance[k].append(RelativeDistance[k][-1])\n",
    "    Bearing[k] = [i for j, i in enumerate(Bearing[k]) if j not in outlier]\n",
    "    Bearing[k].append(Bearing[k][-1])\n",
    "    Delta_Time[k] = [i for j, i in enumerate(Delta_Time[k]) if j not in outlier]\n",
    "    \n",
    "    SegmentNumber[k] = SegmentNumber[k] - len(outlier) #decrease the number of points in the Segment \n",
    "\n",
    "    # Now remove all outlier Segments, where their acceleration exceeds the max acceleration.\n",
    "    # Then, remove their corresponding points from other channels.\n",
    "    Temp_ACC = []\n",
    "    outlier = []\n",
    "    for i in range(len(Speed[k]) - 1):\n",
    "        DeltaSpeed = Speed[k][i+1] - Speed[k][i]\n",
    "        ACC = DeltaSpeed/Delta_Time[k][i]\n",
    "        if abs(ACC) > 10:\n",
    "            outlier.append(i)\n",
    "        Temp_ACC.append(ACC)\n",
    "\n",
    "    Temp_ACC = [i for j, i in enumerate(Temp_ACC) if j not in outlier]\n",
    "    if len(Temp_ACC) < 10:\n",
    "        SegmentNumber[k] = 0\n",
    "        NoOfOutlier += 1\n",
    "        continue\n",
    "    Acceleration[k] = Temp_ACC\n",
    "    Acceleration[k].append(Acceleration[k][-1])\n",
    "    Bus_All_Segment[k] = [i for j, i in enumerate(Bus_All_Segment[k]) if j not in outlier]\n",
    "    Rail_All_Segment[k] = [i for j, i in enumerate(Rail_All_Segment[k]) if j not in outlier]\n",
    "    Traffic_All_Segment[k] = [i for j, i in enumerate(Traffic_All_Segment[k]) if j not in outlier]                        \n",
    "    Speed[k] = [i for j, i in enumerate(Speed[k]) if j not in outlier]\n",
    "    RelativeDistance[k] = [i for j, i in enumerate(RelativeDistance[k]) if j not in outlier]\n",
    "    Bearing[k] = [i for j, i in enumerate(Bearing[k]) if j not in outlier]\n",
    "    Delta_Time[k] = [i for j, i in enumerate(Delta_Time[k]) if j not in outlier]\n",
    "\n",
    "    SegmentNumber[k] = SegmentNumber[k] - len(outlier)\n",
    "\n",
    "    # Now remove all outlier Segments, where their jerk exceeds the max speed.\n",
    "    # Then, remove their corresponding points from other channels.\n",
    "\n",
    "    Temp_J = []\n",
    "    outlier = []\n",
    "    for i in range(len(Acceleration[k]) - 1):\n",
    "        Diff = Acceleration[k][i+1] - Acceleration[k][i]\n",
    "        J = Diff/Delta_Time[k][i]\n",
    "        Temp_J.append(J)\n",
    "\n",
    "    Temp_J = [i for j, i in enumerate(Temp_J) if j not in outlier]\n",
    "    if len(Temp_J) < 10:\n",
    "        SegmentNumber[k] = 0\n",
    "        NoOfOutlier += 1\n",
    "        continue\n",
    "\n",
    "    Jerk[k] = Temp_J\n",
    "    Jerk[k].append(Jerk[k][-1])\n",
    "    Bus_All_Segment[k] = [i for j, i in enumerate(Bus_All_Segment[k]) if j not in outlier]\n",
    "    Rail_All_Segment[k] = [i for j, i in enumerate(Rail_All_Segment[k]) if j not in outlier]\n",
    "    Traffic_All_Segment[k] = [i for j, i in enumerate(Traffic_All_Segment[k]) if j not in outlier] \n",
    "    Speed[k] = [i for j, i in enumerate(Speed[k]) if j not in outlier]\n",
    "    Acceleration[k] = [i for j, i in enumerate(Acceleration[k]) if j not in outlier]\n",
    "    RelativeDistance[k] = [i for j, i in enumerate(RelativeDistance[k]) if j not in outlier]\n",
    "    Bearing[k] = [i for j, i in enumerate(Bearing[k]) if j not in outlier]\n",
    "    Delta_Time[k] = [i for j, i in enumerate(Delta_Time[k]) if j not in outlier]\n",
    "\n",
    "    SegmentNumber[k] = SegmentNumber[k] - len(outlier)\n",
    "    # End of Jerk outlier detection.\n",
    "\n",
    "    # Compute Breating Rate from Bearing, and Velocity change from Speed\n",
    "    for i in range(len(Bearing[k]) - 1):\n",
    "        Diff = abs(Bearing[k][i+1] - Bearing[k][i])\n",
    "        BearingRate[k].append(Diff)\n",
    "    BearingRate[k].append(BearingRate[k][-1])\n",
    "\n",
    "    for i in range(len(Speed[k]) - 1):\n",
    "        Diff = abs(Speed[k][i+1] - Speed[k][i])\n",
    "        if Speed[k][i] != 0:\n",
    "            Velocity_Change[k].append(Diff/Speed[k][i])\n",
    "        else:\n",
    "            Velocity_Change[k].append(1)\n",
    "    Velocity_Change[k].append(Velocity_Change[k][-1])\n",
    "        \n",
    "        \n",
    "    # Now we apply the smoothing filter on each Segment:\n",
    "    def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "        r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
    "        The Savitzky-Golay filter removes high frequency noise from data.\n",
    "        It has the advantage of preserving the original shape and\n",
    "        features of the signal better than other types of filtering\n",
    "        approaches, such as moving averages techniques.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array_like, shape (N,)\n",
    "            the values of the time history of the signal.\n",
    "            window_size : int\n",
    "            the length of the window. Must be an odd integer number.\n",
    "        order : int\n",
    "            the order of the polynomial used in the filtering.\n",
    "            Must be less then `window_size` - 1.\n",
    "        deriv: int\n",
    "            the order of the derivative to compute (default = 0 means only smoothing)\n",
    "        Returns\n",
    "        -------\n",
    "        ys : ndarray, shape (N)\n",
    "            the smoothed signal (or it's n-th derivative).\n",
    "        Notes\n",
    "        -----\n",
    "        The Savitzky-Golay is a type of low-pass filter, particularly\n",
    "        suited for smoothing noisy data. The main idea behind this\n",
    "        approach is to make for each point a least-square fit with a\n",
    "        polynomial of high order over a odd-sized window centered at\n",
    "        the point.\n",
    "        Examples\n",
    "        --------\n",
    "        t = np.linspace(-4, 4, 500)\n",
    "        y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
    "        ysg = savitzky_golay(y, window_size=31, order=4)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(t, y, label='Noisy signal')\n",
    "        plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
    "        plt.plot(t, ysg, 'r', label='Filtered signal')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        References\n",
    "        ----------\n",
    "        .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
    "        Data by Simplified Least Squares Procedures. Analytical\n",
    "           Chemistry, 1964, 36 (8), pp 1627-1639.\n",
    "        .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
    "        W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
    "           Cambridge University Press ISBN-13: 9780521880688\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from math import factorial\n",
    "\n",
    "        try:\n",
    "            window_size = np.abs(np.int(window_size))\n",
    "            order = np.abs(np.int(order))\n",
    "        except ValueError:\n",
    "            raise ValueError(\"window_size and order have to be of type int\")\n",
    "        if window_size % 2 != 1 or window_size < 1:\n",
    "            raise TypeError(\"window_size size must be a positive odd number\")\n",
    "        if window_size < order + 2:\n",
    "            raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "        order_range = range(order + 1)\n",
    "        half_window = (window_size - 1) // 2\n",
    "        # precompute coefficients\n",
    "        b = np.mat([[k ** i for i in order_range] for k in range(-half_window, half_window + 1)])\n",
    "        m = np.linalg.pinv(b).A[deriv] * rate ** deriv * factorial(deriv)\n",
    "        # pad the signal at the extremes with\n",
    "        # values taken from the signal itself\n",
    "        firstvals = y[0] - np.abs(y[1:half_window + 1][::-1] - y[0])\n",
    "        lastvals = y[-1] + np.abs(y[-half_window - 1:-1][::-1] - y[-1])\n",
    "        y = np.concatenate((firstvals, y, lastvals))\n",
    "        return np.convolve(m[::-1], y, mode='valid')\n",
    "\n",
    "    # Smoothing process\n",
    "    RelativeDistance[k] = savitzky_golay(np.array(RelativeDistance[k]), 9, 3)\n",
    "    Speed[k] = savitzky_golay(np.array(Speed[k]), 9, 3)\n",
    "    Acceleration[k] = savitzky_golay(np.array(Acceleration[k]), 9, 3)\n",
    "    Jerk[k] = savitzky_golay(np.array(Jerk[k]), 9, 3)\n",
    "    BearingRate[k] = savitzky_golay(np.array(BearingRate[k]), 9, 3)\n",
    "    Bus_All_Segment[k]= savitzky_golay(np.array(Bus_All_Segment[k]), 9, 3)\n",
    "    Rail_All_Segment[k]= savitzky_golay(np.array(Rail_All_Segment[k]), 9, 3)\n",
    "    Traffic_All_Segment[k]= savitzky_golay(np.array(Traffic_All_Segment[k]), 9, 3)\n",
    "        \n",
    "Total_RelativeDistance.append(RelativeDistance)\n",
    "Total_Speed.append(Speed)\n",
    "Total_Acceleration.append(Acceleration)\n",
    "Total_Jerk.append(Jerk)\n",
    "Total_BearingRate.append(BearingRate)\n",
    "Total_BusLine.append(Bus_All_Segment)\n",
    "Total_Railway.append(Rail_All_Segment)\n",
    "Total_Traffic.append(Traffic_All_Segment)                       \n",
    "Total_Delta_Time.append(Delta_Time)\n",
    "Total_Velocity_Change.append(Velocity_Change)\n",
    "Total_Stage.append(Stage)\n",
    "Total_SegmentNumber.append(SegmentNumber)\n",
    "Total_Outlier.append(User_outlier)\n",
    "Total_Segment_InSequence = Total_Segment_InSequence + SegmentNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving results\n",
    "with open('Data/Revised_Unlabeled_40_final.pickle', 'wb') as f:\n",
    "    pickle.dump([Total_RelativeDistance, Total_Speed, Total_Acceleration, Total_Jerk, Total_BearingRate, Total_Stage,\n",
    "                 Total_SegmentNumber, Total_Segment_InSequence, Total_Delta_Time, Total_Velocity_Change,Total_BusLine,Total_Railway,Total_Traffic], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unifying segment size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/Revised_Unlabeled_40_final.pickle'\n",
    "# Each of the following variables contain multiple lists, where each list belongs to a user\n",
    "with open(filename, 'rb') as f:\n",
    "    Total_RelativeDistance, Total_Speed, Total_Acceleration, Total_Jerk, Total_BearingRate, Total_Stage,\\\n",
    "    Total_SegmentNumber, Total_Segment_InSequence, Total_Delta_Time, Total_Velocity_Change,Total_BusLine,Total_Railway,Total_Traffic = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_SegmentID =[[int(i) for i in SegmentID]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72977"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Total_SegmentID[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data in the Keras form\n",
    "# Threshold: Is the max of number of GPS point in an Segment\n",
    "#Padding Segments to 200 threshold \n",
    "Threshold = 200\n",
    "Zero_Segment = [i for i, item in enumerate(Total_Segment_InSequence) if item == 0]\n",
    "Number_of_Segment = len(Total_Segment_InSequence) - len(Zero_Segment)\n",
    "TotalInput = np.zeros((Number_of_Segment, 1, Threshold, 8), dtype=float)\n",
    "FinalStage = np.zeros((Number_of_Segment, 1), dtype=int)\n",
    "\n",
    "counter = 0\n",
    "for k in range(len(Total_SegmentNumber)):\n",
    "    # Create Keras shape with 8 channels for each user\n",
    "    #  There are 8 channels(in order: RelativeDistance, Speed, Acceleration, BearingRate)\n",
    "    RD = Total_RelativeDistance[k]\n",
    "    SP = Total_Speed[k]\n",
    "    AC = Total_Acceleration[k]\n",
    "    J = Total_Jerk[k]\n",
    "    BR = Total_BearingRate[k]\n",
    "    LA = Total_SegmentID[k]#Total_Stage\n",
    "    BS=Total_BusLine[k]\n",
    "    RL=Total_Railway[k]\n",
    "    TR=Total_Traffic[k]\n",
    "\n",
    "    \n",
    "    # IN: the Segments and number of GPS points in each Segment for each user k\n",
    "    IN = Total_SegmentNumber[k]\n",
    "\n",
    "    for i in range(len(IN)):\n",
    "        end = IN[i]\n",
    "        if end == 0 or sum(RD[i]) == 0:\n",
    "            continue\n",
    "        TotalInput[counter, 0, 0:end, 0] = SP[i]\n",
    "        TotalInput[counter, 0, 0:end, 1] = AC[i]\n",
    "        TotalInput[counter, 0, 0:end, 2] = J[i]\n",
    "        TotalInput[counter, 0, 0:end, 3] = BR[i]\n",
    "        TotalInput[counter, 0, 0:end, 4] = BS[i]           \n",
    "        TotalInput[counter, 0, 0:end, 5] = RL[i]\n",
    "        TotalInput[counter, 0, 0:end, 6] = TR[i]\n",
    "        TotalInput[counter, 0, 0:end, 7] = RD[i]\n",
    "        \n",
    "        FinalStage[counter, 0] = LA[i]\n",
    "        counter += 1\n",
    "\n",
    "TotalInput = TotalInput[:counter, :, :, :]\n",
    "FinalStage = FinalStage[:counter, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Revised_KerasData_Smoothing_8_40_final_segmentID.pickle', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([TotalInput, FinalStage], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
