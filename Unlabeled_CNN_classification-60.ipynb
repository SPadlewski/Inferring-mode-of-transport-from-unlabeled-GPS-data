{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked generalization with linear meta model on blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import load_model\n",
    "from numpy import dstack\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:62: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded models/model_CNN_1.h5\n",
      ">loaded models/model_CNN_2.h5\n",
      ">loaded models/model_CNN_3.h5\n",
      ">loaded models/model_CNN_4.h5\n",
      ">loaded models/model_CNN_5.h5\n",
      ">loaded models/model_CNN_6.h5\n",
      ">loaded models/model_CNN_7.h5\n",
      ">loaded models/model_CNN_8.h5\n",
      ">loaded models/model_CNN_9.h5\n",
      ">loaded models/model_CNN_10.h5\n",
      ">loaded models/model_CNN_11.h5\n",
      ">loaded models/model_CNN_12.h5\n",
      ">loaded models/model_CNN_13.h5\n",
      ">loaded models/model_CNN_14.h5\n",
      "Loaded 14 models\n",
      "Model Accuracy: 0.801\n",
      "Model Accuracy: 0.801\n",
      "Model Accuracy: 0.804\n",
      "Model Accuracy: 0.815\n",
      "Model Accuracy: 0.814\n",
      "Model Accuracy: 0.815\n",
      "Model Accuracy: 0.815\n",
      "Model Accuracy: 0.568\n",
      "Model Accuracy: 0.613\n",
      "Model Accuracy: 0.630\n",
      "Model Accuracy: 0.668\n",
      "Model Accuracy: 0.623\n",
      "Model Accuracy: 0.673\n",
      "Model Accuracy: 0.679\n",
      "Stacked Test Accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "\t\tfilename = 'models/model_CNN_' + str(i + 1) + '.h5'\n",
    "\t\t# load model from file\n",
    "\t\tmodel = load_model(filename)\n",
    "\t\t# add to list of members\n",
    "\t\tall_models.append(model)\n",
    "\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models\n",
    "\n",
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def stacked_dataset(members, inputX_M,inputX_G):\n",
    "    stackX = None\n",
    "    for i in range(len(members)):\n",
    "        model=members[i]\n",
    "        if i<7:\n",
    "            # make prediction\n",
    "            yhat = model.predict(inputX_M, verbose=0)\n",
    "            # stack predictions into [rows, members, probabilities]\n",
    "            if stackX is None:\n",
    "                stackX = yhat\n",
    "            else:\n",
    "                stackX = dstack((stackX, yhat))\n",
    "        else:\n",
    "            # make prediction\n",
    "            yhat = model.predict(inputX_G, verbose=0)\n",
    "            # stack predictions into [rows, members, probabilities]\n",
    "            if stackX is None:\n",
    "                stackX = yhat\n",
    "            else:\n",
    "                stackX = dstack((stackX, yhat))            \n",
    "                \n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    return stackX\n",
    "\n",
    "# fit a model based on the outputs from the ensemble members\n",
    "def fit_stacked_model(members, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    inputX_M=inputX[:, :, :, :4]\n",
    "    inputX_G=inputX[:, :, :, 4:]\n",
    "    stackedX = stacked_dataset(members, inputX_M,inputX_G)\n",
    "    # fit standalone model\n",
    "    model = LogisticRegression(max_iter=6500)\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "\n",
    "# make a prediction with the stacked model\n",
    "def stacked_prediction(members, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    inputX_M=inputX[:, :, :, :4]\n",
    "    inputX_G=inputX[:, :, :, 4:]\n",
    "    stackedX = stacked_dataset(members, inputX_M,inputX_G)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat\n",
    "\n",
    "\n",
    "start_time = time.clock()\n",
    "np.random.seed(7)\n",
    "random.seed(7)\n",
    "\n",
    "filename = 'Combined Trajectory_Label_Geolife/Revised_KerasData_Smoothing_GIS_new_8.pickle'\n",
    "\n",
    "with open(filename, mode='rb') as f:\n",
    "    TotalInput, FinalLabel = pickle.load(f, encoding='latin1')  # Also can use the encoding 'iso-8859-1'\n",
    "\n",
    "    \n",
    "filename = 'Data/Revised_KerasData_Smoothing_8_60_final.pickle'\n",
    "\n",
    "with open(filename, mode='rb') as f:\n",
    "    TotalInput_UN, FinalStage_UN = pickle.load(f, encoding='latin1')  # Also can use the encoding 'iso-8859-1'\n",
    "    \n",
    "    \n",
    "NoClass = len(list(set(np.ndarray.flatten(FinalLabel))))\n",
    "Threshold = len(TotalInput[0, 0, :, 0])\n",
    "\n",
    "# Making training and test data: 80% Training, 20% Test\n",
    "Train_X, Test_X, Train_Y, Test_Y_ori = train_test_split(TotalInput, FinalLabel, test_size=0.20, random_state=7)\n",
    "\n",
    "Test_M_X=Test_X[:, :, :, :4]\n",
    "Test_G_X=Test_X[:, :, :, 4:]\n",
    "\n",
    "\n",
    "# load all models\n",
    "n_members = 14\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))\n",
    "# evaluate standalone models on test dataset\n",
    "for i in range(len(members)):\n",
    "    model=members[i]\n",
    "    if i <7:\n",
    "        testy_enc = np_utils.to_categorical(Test_Y_ori, num_classes=NoClass)\n",
    "        _, acc = model.evaluate(Test_M_X, testy_enc, verbose=0)\n",
    "        print('Model Accuracy: %.3f' % acc)\n",
    "    else:\n",
    "        testy_enc = np_utils.to_categorical(Test_Y_ori, num_classes=NoClass)\n",
    "        _, acc = model.evaluate(Test_G_X, testy_enc, verbose=0)\n",
    "        print('Model Accuracy: %.3f' % acc)\n",
    "# fit stacked model using the ensemble\n",
    "model = fit_stacked_model(members, Test_X, Test_Y_ori)\n",
    "# evaluate model on test set\n",
    "yhat = stacked_prediction(members, model, Test_X)\n",
    "acc = accuracy_score(Test_Y_ori, yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading segments for classification \n",
    "filename = 'Data/Revised_KerasData_Smoothing_8_60_final_segmentID.pickle'\n",
    "\n",
    "with open(filename, mode='rb') as f:\n",
    "    TotalInput_UN, FinalStage_UN = pickle.load(f, encoding='latin1')  # Also can use the encoding 'iso-8859-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting validation sample\n",
    "Train_X, Test_X, Train_Y, Test_Y_ori = train_test_split(TotalInput_UN, FinalStage_UN, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 565 ms, total: 19.2 s\n",
      "Wall time: 6.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#classifiaction\n",
    "yhat = stacked_prediction(members, model, Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation sample size\n",
    "len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading segments GPS points for validation and plotting\n",
    "filename = 'Data/Proximity+200_Unlabeled_60_final.pickle'\n",
    "with open(filename, 'rb') as f:\n",
    "    Bus_All_Segment,SegmentID,Rail_All_Segment, Traffic_All_Segment, Stage, Data_All_Segment, SegmentNumber = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# assigning segments ID to predicted modes\n",
    "import pandas as pd\n",
    "segments_index=[i for i,x in enumerate(SegmentID) if x in Test_Y_ori]\n",
    "\n",
    "df_pred = pd.DataFrame(columns = ['lat','lon','timestamp','segmentID','stageID','pred_mode'])\n",
    "for i in range(len(segments_index)):\n",
    "    df = pd.DataFrame(Data_All_Segment[segments_index[i]])\n",
    "    df=df.rename(columns={0:'lat',1:'lon',2:'timestamp'})\n",
    "    df['segmentID']=Test_Y_ori[i]\n",
    "    df['stageID']=Stage[segments_index[i]]\n",
    "    df['pred_mode']=yhat[i]   \n",
    "    df_pred=pd.concat([df_pred,df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>segmentID</th>\n",
       "      <th>stageID</th>\n",
       "      <th>pred_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.506708</td>\n",
       "      <td>-0.106041</td>\n",
       "      <td>44333.643808</td>\n",
       "      <td>1332</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.506749</td>\n",
       "      <td>-0.105608</td>\n",
       "      <td>44333.644028</td>\n",
       "      <td>1332</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.506749</td>\n",
       "      <td>-0.105608</td>\n",
       "      <td>44333.644248</td>\n",
       "      <td>1332</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.506737</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>44333.644294</td>\n",
       "      <td>1332</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.506721</td>\n",
       "      <td>-0.105683</td>\n",
       "      <td>44333.644329</td>\n",
       "      <td>1332</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74808</th>\n",
       "      <td>51.586065</td>\n",
       "      <td>-0.061815</td>\n",
       "      <td>44338.424688</td>\n",
       "      <td>5737</td>\n",
       "      <td>16078.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74809</th>\n",
       "      <td>51.586073</td>\n",
       "      <td>-0.061813</td>\n",
       "      <td>44338.424711</td>\n",
       "      <td>5737</td>\n",
       "      <td>16078.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74810</th>\n",
       "      <td>51.586115</td>\n",
       "      <td>-0.061833</td>\n",
       "      <td>44338.424734</td>\n",
       "      <td>5737</td>\n",
       "      <td>16078.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74811</th>\n",
       "      <td>51.586109</td>\n",
       "      <td>-0.061843</td>\n",
       "      <td>44338.424757</td>\n",
       "      <td>5737</td>\n",
       "      <td>16078.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74812</th>\n",
       "      <td>51.586109</td>\n",
       "      <td>-0.061843</td>\n",
       "      <td>44338.424780</td>\n",
       "      <td>5737</td>\n",
       "      <td>16078.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74813 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat       lon     timestamp segmentID  stageID pred_mode\n",
       "0      51.506708 -0.106041  44333.643808      1332      6.0         4\n",
       "1      51.506749 -0.105608  44333.644028      1332      6.0         4\n",
       "2      51.506749 -0.105608  44333.644248      1332      6.0         4\n",
       "3      51.506737 -0.105656  44333.644294      1332      6.0         4\n",
       "4      51.506721 -0.105683  44333.644329      1332      6.0         4\n",
       "...          ...       ...           ...       ...      ...       ...\n",
       "74808  51.586065 -0.061815  44338.424688      5737  16078.0         3\n",
       "74809  51.586073 -0.061813  44338.424711      5737  16078.0         3\n",
       "74810  51.586115 -0.061833  44338.424734      5737  16078.0         3\n",
       "74811  51.586109 -0.061843  44338.424757      5737  16078.0         3\n",
       "74812  51.586109 -0.061843  44338.424780      5737  16078.0         3\n",
       "\n",
       "[74813 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data frame with predicted modes\n",
    "#df_pred.to_pickle('Data/segments_60_1_percent_predictions.pkl')\n",
    "df_pred = pd.read_pickle('Data/segments_60_1_percent_predictions.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1315, 4840, 5911, 1017, 6827, 4430, 164, 4084, 7326, 6009, 3770,\n",
       "       1961, 1805, 920, 2128, 6056, 2044, 803, 5003, 5740, 4117, 3690,\n",
       "       315, 1057, 6028, 5461, 5481, 2984, 2714, 7100], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting segments with modes 0,1,2,3 or 4 (walk,bike,bus,driving or train)\n",
    "df_pred[df_pred.pred_mode==1].segmentID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecing a segment for validation\n",
    "import skmob\n",
    "import folium\n",
    "\n",
    "df_pred[df_pred.segmentID==5740]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting selected segment for validation\n",
    "\n",
    "data= skmob.TrajDataFrame(\n",
    "df_pred[df_pred.segmentID==5740],\n",
    "latitude= \"lat\",\n",
    "longitude=\"lon\",\n",
    "datetime='timestamp',\n",
    "parameters= {1:'segmentID'})\n",
    "\n",
    "#plotting\n",
    "data.plot_trajectory(zoom=12, weight=10, opacity=0.9, tiles='OpenStreetMap'\n",
    "                     ,start_end_markers=True,dashArray='5, 5')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
